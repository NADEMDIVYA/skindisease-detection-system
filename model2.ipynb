{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0556853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 1638 images for class '1. Eczema 1677'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1638 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1638/1638 [00:08<00:00, 201.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2000 images for class '10. Warts Molluscum and other Viral Infections - 2103'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:10<00:00, 190.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 1581 images for class '11.Unknown'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1581/1581 [00:22<00:00, 69.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2000 images for class '2. Melanoma 15.75k'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:10<00:00, 186.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 1254 images for class '3. Atopic Dermatitis - 1.25k'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [00:06<00:00, 197.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2000 images for class '4. Basal Cell Carcinoma (BCC) 3323'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:13<00:00, 146.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2000 images for class '5. Melanocytic Nevi (NV) - 7970'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:20<00:00, 96.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2000 images for class '6. Benign Keratosis-like Lesions (BKL) 2624'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 209.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2000 images for class '7. Psoriasis pictures Lichen Planus and related diseases - 2k'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:08<00:00, 230.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 1847 images for class '8. Seborrheic Keratoses and other Benign Tumors - 1.8k'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1847/1847 [00:07<00:00, 239.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 1702 images for class '9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1702/1702 [00:07<00:00, 226.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset balanced and saved to: balanced-dataset-skin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to your dataset root (where each class folder is)\n",
    "dataset_path = 'dataset-skin'\n",
    "\n",
    "# Maximum number of images per class\n",
    "MAX_IMAGES = 2000\n",
    "\n",
    "# Whether to randomly select images to keep\n",
    "RANDOMIZE = True\n",
    "\n",
    "# Output path for the balanced dataset\n",
    "output_path = 'balanced-dataset-skin'\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_dir = os.path.join(dataset_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    \n",
    "    images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if RANDOMIZE:\n",
    "        random.shuffle(images)\n",
    "\n",
    "    selected_images = images[:MAX_IMAGES]  # Keep only MAX_IMAGES\n",
    "\n",
    "    new_class_dir = os.path.join(output_path, class_name)\n",
    "    os.makedirs(new_class_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Copying {len(selected_images)} images for class '{class_name}'...\")\n",
    "\n",
    "    for img_file in tqdm(selected_images):\n",
    "        src = os.path.join(class_dir, img_file)\n",
    "        dst = os.path.join(new_class_dir, img_file)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "print(\"\\n✅ Dataset balanced and saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa4e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18540 images belonging to 11 classes.\n",
      "Found 4628 images belonging to 11 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1809s\u001b[0m 3s/step - accuracy: 0.4613 - loss: 1.5158 - val_accuracy: 0.2986 - val_loss: 4.1198 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1744s\u001b[0m 3s/step - accuracy: 0.6703 - loss: 0.8793 - val_accuracy: 0.3496 - val_loss: 3.9676 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1686s\u001b[0m 3s/step - accuracy: 0.7205 - loss: 0.7398 - val_accuracy: 0.4047 - val_loss: 2.5785 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2152s\u001b[0m 4s/step - accuracy: 0.7447 - loss: 0.6771 - val_accuracy: 0.5143 - val_loss: 1.9848 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2015s\u001b[0m 3s/step - accuracy: 0.7750 - loss: 0.6099 - val_accuracy: 0.5337 - val_loss: 2.2278 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1686s\u001b[0m 3s/step - accuracy: 0.7936 - loss: 0.5686 - val_accuracy: 0.5359 - val_loss: 1.9655 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1639s\u001b[0m 3s/step - accuracy: 0.8249 - loss: 0.4950 - val_accuracy: 0.5393 - val_loss: 2.3932 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1438s\u001b[0m 2s/step - accuracy: 0.8295 - loss: 0.4627 - val_accuracy: 0.5374 - val_loss: 2.1331 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1446s\u001b[0m 2s/step - accuracy: 0.8435 - loss: 0.4311 - val_accuracy: 0.4914 - val_loss: 2.7290 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1442s\u001b[0m 2s/step - accuracy: 0.8663 - loss: 0.3704 - val_accuracy: 0.5382 - val_loss: 2.6074 - learning_rate: 3.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1572s\u001b[0m 3s/step - accuracy: 0.8805 - loss: 0.3359 - val_accuracy: 0.5527 - val_loss: 2.4368 - learning_rate: 3.0000e-05\n",
      "✅ Model trained and best version saved as 'best_skin_model.keras'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "DATA_DIR = 'balanced-dataset-skin'\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "# ---------------- DATA AUGMENTATION ----------------\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ---------------- MODEL ----------------\n",
    "base_model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = True  # ✅ Train entire model directly\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# ---------------- COMPILE ----------------\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ---------------- CALLBACKS ----------------\n",
    "checkpoint = ModelCheckpoint(\"best_skin_model.keras\", monitor='val_accuracy', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6)\n",
    "\n",
    "# ---------------- TRAIN ----------------\n",
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "print(\"✅ Model trained and best version saved as 'best_skin_model.keras'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
